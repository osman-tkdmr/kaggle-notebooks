{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"Data/train.csv\")\n",
    "test = pd.read_csv(\"Data/test.csv\")\n",
    "extra = pd.read_csv(\"Data/training_extra.csv\")\n",
    "submission = pd.read_csv(\"Data/sample_submission.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "merge4knn = pd.concat([train.drop([\"id\", \"Price\"], axis=1), test.drop([\"id\"], axis=1), extra.drop([\"id\", \"Price\"], axis=1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Brand",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Material",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Size",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Compartments",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Laptop Compartment",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Waterproof",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Style",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Color",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Weight Capacity (kg)",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "9a9b08af-3f0c-4caa-9d49-ba75a30c52d0",
       "rows": [
        [
         "0",
         "Jansport",
         "Leather",
         "Medium",
         "7.0",
         "Yes",
         "No",
         "Tote",
         "Black",
         "11.611722805222309"
        ],
        [
         "1",
         "Jansport",
         "Canvas",
         "Small",
         "10.0",
         "Yes",
         "Yes",
         "Messenger",
         "Green",
         "27.07853658053123"
        ],
        [
         "2",
         "Under Armour",
         "Leather",
         "Small",
         "2.0",
         "Yes",
         "No",
         "Messenger",
         "Red",
         "16.643759949103497"
        ],
        [
         "3",
         "Nike",
         "Nylon",
         "Small",
         "8.0",
         "Yes",
         "No",
         "Messenger",
         "Green",
         "12.937220306632067"
        ],
        [
         "4",
         "Adidas",
         "Canvas",
         "Medium",
         "1.0",
         "Yes",
         "Yes",
         "Messenger",
         "Green",
         "17.749338465908988"
        ]
       ],
       "shape": {
        "columns": 9,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Brand</th>\n",
       "      <th>Material</th>\n",
       "      <th>Size</th>\n",
       "      <th>Compartments</th>\n",
       "      <th>Laptop Compartment</th>\n",
       "      <th>Waterproof</th>\n",
       "      <th>Style</th>\n",
       "      <th>Color</th>\n",
       "      <th>Weight Capacity (kg)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Jansport</td>\n",
       "      <td>Leather</td>\n",
       "      <td>Medium</td>\n",
       "      <td>7.0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Tote</td>\n",
       "      <td>Black</td>\n",
       "      <td>11.611723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Jansport</td>\n",
       "      <td>Canvas</td>\n",
       "      <td>Small</td>\n",
       "      <td>10.0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Messenger</td>\n",
       "      <td>Green</td>\n",
       "      <td>27.078537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Under Armour</td>\n",
       "      <td>Leather</td>\n",
       "      <td>Small</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Messenger</td>\n",
       "      <td>Red</td>\n",
       "      <td>16.643760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Nike</td>\n",
       "      <td>Nylon</td>\n",
       "      <td>Small</td>\n",
       "      <td>8.0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Messenger</td>\n",
       "      <td>Green</td>\n",
       "      <td>12.937220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Adidas</td>\n",
       "      <td>Canvas</td>\n",
       "      <td>Medium</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Messenger</td>\n",
       "      <td>Green</td>\n",
       "      <td>17.749338</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Brand Material    Size  Compartments Laptop Compartment Waterproof  \\\n",
       "0      Jansport  Leather  Medium           7.0                Yes         No   \n",
       "1      Jansport   Canvas   Small          10.0                Yes        Yes   \n",
       "2  Under Armour  Leather   Small           2.0                Yes         No   \n",
       "3          Nike    Nylon   Small           8.0                Yes         No   \n",
       "4        Adidas   Canvas  Medium           1.0                Yes        Yes   \n",
       "\n",
       "       Style  Color  Weight Capacity (kg)  \n",
       "0       Tote  Black             11.611723  \n",
       "1  Messenger  Green             27.078537  \n",
       "2  Messenger    Red             16.643760  \n",
       "3  Messenger  Green             12.937220  \n",
       "4  Messenger  Green             17.749338  "
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merge4knn.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Brand                   132985\n",
       "Material                116575\n",
       "Size                     92166\n",
       "Compartments                 0\n",
       "Laptop Compartment      103495\n",
       "Waterproof               99135\n",
       "Style                   109333\n",
       "Color                   140402\n",
       "Weight Capacity (kg)      1885\n",
       "dtype: int64"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merge4knn.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "def knn_categorical_imputation(df, categorical_columns, k=5):\n",
    "    \"\"\"\n",
    "    Fills missing categorical data using K-Nearest Neighbors (KNN) imputation.\n",
    "\n",
    "    Parameters:\n",
    "    df (pd.DataFrame): Input dataframe with missing values.\n",
    "    categorical_columns (list): List of categorical column names to impute.\n",
    "    k (int): Number of neighbors to consider for KNN. Default is 5.\n",
    "\n",
    "    Returns:\n",
    "    pd.DataFrame: Dataframe with missing categorical values filled.\n",
    "    \"\"\"\n",
    "    df_filled = df.copy()\n",
    "    \n",
    "    for col in categorical_columns:\n",
    "        if df_filled[col].isnull().sum() == 0:\n",
    "            continue  # Skip if no missing values\n",
    "        \n",
    "        # Split data into training and missing sets\n",
    "        train_data = df_filled.dropna(subset=[col])\n",
    "        test_data = df_filled[df_filled[col].isnull()]\n",
    "        \n",
    "        if test_data.empty:\n",
    "            continue\n",
    "        \n",
    "        # Features and target\n",
    "        features = df_filled.columns.drop(col)\n",
    "        X_train = train_data[features]\n",
    "        y_train = train_data[col]\n",
    "        X_test = test_data[features]\n",
    "        \n",
    "        # Preprocessors for numerical and categorical features\n",
    "        numerical_features = X_train.select_dtypes(include=['int64', 'float64']).columns\n",
    "        categorical_features = X_train.select_dtypes(include=['object', 'category']).columns\n",
    "        \n",
    "        numerical_transformer = Pipeline(steps=[\n",
    "            ('imputer', SimpleImputer(strategy='mean')),\n",
    "            ('scaler', StandardScaler())\n",
    "        ])\n",
    "        \n",
    "        categorical_transformer = Pipeline(steps=[\n",
    "            ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "            ('encoder', OneHotEncoder(handle_unknown='ignore'))\n",
    "        ])\n",
    "        \n",
    "        preprocessor = ColumnTransformer(transformers=[\n",
    "            ('num', numerical_transformer, numerical_features),\n",
    "            ('cat', categorical_transformer, categorical_features)\n",
    "        ])\n",
    "        \n",
    "        # KNN Classifier Pipeline\n",
    "        knn_pipeline = Pipeline(steps=[\n",
    "            ('preprocessor', preprocessor),\n",
    "            ('classifier', KNeighborsClassifier(n_neighbors=k))\n",
    "        ])\n",
    "        \n",
    "        knn_pipeline.fit(X_train, y_train)\n",
    "        predicted = knn_pipeline.predict(X_test)\n",
    "        \n",
    "        # Update the dataframe with imputed values\n",
    "        df_filled.loc[df_filled[col].isnull(), col] = predicted\n",
    "    \n",
    "    return df_filled\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "def knn_numerical_imputation(df, numerical_columns, k=5):\n",
    "    \"\"\"\n",
    "    Fills missing numerical data using K-Nearest Neighbors (KNN) regression.\n",
    "\n",
    "    Parameters:\n",
    "    df (pd.DataFrame): Input dataframe with missing values.\n",
    "    numerical_columns (list): List of numerical column names to impute.\n",
    "    k (int): Number of neighbors to consider for KNN. Default is 5.\n",
    "\n",
    "    Returns:\n",
    "    pd.DataFrame: Dataframe with missing numerical values filled.\n",
    "    \"\"\"\n",
    "    df_filled = df.copy()\n",
    "    \n",
    "    for col in numerical_columns:\n",
    "        if df_filled[col].isnull().sum() == 0:\n",
    "            continue  # Skip if no missing values\n",
    "        \n",
    "        # Split data into training and missing sets\n",
    "        train_data = df_filled.dropna(subset=[col])\n",
    "        test_data = df_filled[df_filled[col].isnull()]\n",
    "        \n",
    "        if test_data.empty:\n",
    "            continue\n",
    "        \n",
    "        # Features and target\n",
    "        features = df_filled.columns.drop(col)\n",
    "        X_train = train_data[features]\n",
    "        y_train = train_data[col]\n",
    "        X_test = test_data[features]\n",
    "        \n",
    "        # Preprocessors for numerical and categorical features\n",
    "        numerical_features = X_train.select_dtypes(include=['int64', 'float64']).columns\n",
    "        categorical_features = X_train.select_dtypes(include=['object', 'category']).columns\n",
    "        \n",
    "        numerical_transformer = Pipeline(steps=[\n",
    "            ('imputer', SimpleImputer(strategy='mean')),  # Impute missing numerical features\n",
    "            ('scaler', StandardScaler())  # Standardize numerical features\n",
    "        ])\n",
    "        \n",
    "        categorical_transformer = Pipeline(steps=[\n",
    "            ('imputer', SimpleImputer(strategy='most_frequent')),  # Impute missing categorical features\n",
    "            ('encoder', OneHotEncoder(handle_unknown='ignore'))  # Encode categorical features\n",
    "        ])\n",
    "        \n",
    "        preprocessor = ColumnTransformer(transformers=[\n",
    "            ('num', numerical_transformer, numerical_features),\n",
    "            ('cat', categorical_transformer, categorical_features)\n",
    "        ])\n",
    "        \n",
    "        # KNN Regressor Pipeline\n",
    "        knn_pipeline = Pipeline(steps=[\n",
    "            ('preprocessor', preprocessor),\n",
    "            ('regressor', KNeighborsRegressor(n_neighbors=k))\n",
    "        ])\n",
    "        \n",
    "        knn_pipeline.fit(X_train, y_train)\n",
    "        predicted = knn_pipeline.predict(X_test)\n",
    "        \n",
    "        # Update the dataframe with imputed values\n",
    "        df_filled.loc[df_filled[col].isnull(), col] = predicted\n",
    "    \n",
    "    return df_filled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "miss_cat_cols = list(merge4knn.columns)\n",
    "miss_cat_cols.remove(\"Weight Capacity (kg)\")\n",
    "miss_cat_cols.remove(\"Compartments\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Brand',\n",
       " 'Material',\n",
       " 'Size',\n",
       " 'Laptop Compartment',\n",
       " 'Waterproof',\n",
       " 'Style',\n",
       " 'Color']"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "miss_cat_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "filled_data = knn_categorical_imputation(merge4knn, miss_cat_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "filled_data[\"Weight Capacity (kg)\"] = knn_numerical_imputation(filled_data,[\"Weight Capacity (kg)\"])[\"Weight Capacity (kg)\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Brand                   0\n",
       "Material                0\n",
       "Size                    0\n",
       "Compartments            0\n",
       "Laptop Compartment      0\n",
       "Waterproof              0\n",
       "Style                   0\n",
       "Color                   0\n",
       "Weight Capacity (kg)    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filled_data.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "filled_train = filled_data.iloc[:300000].copy()\n",
    "filled_test = filled_data.iloc[300000:500000].copy()\n",
    "filled_extra = filled_data.iloc[500000:].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "filled_train[[\"id\",\"Price\"]] = train[[\"id\",\"Price\"]]\n",
    "filled_extra[[\"id\",\"Price\"]] = extra[[\"id\",\"Price\"]]\n",
    "filled_test[\"id\"] = test[\"id\"]\n",
    "filled_test[\"Price\"] = pd.NA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "filled_train.to_csv(\"Data/filled_train.csv\", index=False)\n",
    "filled_test.to_csv(\"Data/filled_test.csv\", index=False)\n",
    "filled_extra.to_csv(\"Data/filled_extra.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DataScience",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
